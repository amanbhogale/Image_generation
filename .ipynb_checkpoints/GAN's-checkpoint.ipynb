{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507d53e8-4451-48c6-a30a-566346f9a8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.datasets.cifar10 import load_data\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad64597-bbf9-4cd6-9235-6db219c2c23a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 28196864/170498071 [===>..........................] - ETA: 10:58"
     ]
    }
   ],
   "source": [
    "(train_x , train_y) , (test_x , test_y) = load_data()\n",
    "for i in range(49):\n",
    "    pyplot.subplot(7 , 7 , 1 +i)\n",
    "    pyplot.axis('off')\n",
    "    pyplot.imshow(train_x[i])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5592f9e-15a3-45ee-89c3-954c411b8ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import  Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils import  plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bea05d-cbe6-424d-83ad-8305af39cf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(32 , 32 , 3)):\n",
    "    model = Sequential()\n",
    "    #normal \n",
    "    model.add(Conv2D(64 , (3 , 3) , padding='same' , input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #downsample\n",
    "    model.add(Conv2D(128 , (3 , 3) , strides=(2 , 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128 , (3 , 3) , strides=(2 , 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256 , (3 , 3) , strides=(2 , 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #classifier\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1 , activation='sigmoid'))\n",
    "    #compile\n",
    "    opt = Adam(lr=0.002 , beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy' , optimizer=opt , metrics=['accuracy'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce30371-84d8-47c6-956c-edc717950778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define model \n",
    "model = define_discriminator()\n",
    "model.summary()\n",
    "plot_model(model , to_file='discriminator_plot.png' , show_shapes=True , show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015559c2-8ae4-46ca-a7bc-df87e20ff028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_real_sample():\n",
    "    (train_x , _), (_, _) = load_data()\n",
    "    x = train_x.astype('float32')\n",
    "    #scale from [0, 255] to [-1 ,1 ]\n",
    "    x = (x -127.5)/127.5\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52ffb8-06bb-47a5-90b2-c3751612d6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = load_real_sample()\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e69a01b-56ce-4300-8822-1e5f5ceb4622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_real_sample(dataset , n_samples):\n",
    "    ix = np.random.randint(0 , dataset.shape[0] , n_samples)\n",
    "    x = dataset[ix]\n",
    "    y = np.ones((n_samples , 1))\n",
    "    return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb65c3f-e8ea-4745-bd13-816fdd25ab28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x , y  = generate_real_sample(x , 64)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a0fec-5968-4a72-a435-78ee4e44f9b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_fake_samples(n_samples):\n",
    "    x = np.random.rand(32 * 32 * 3 * n_samples)\n",
    "    x = -1 + x + 2\n",
    "    x = x.reshape((n_samples , 32, 32 ,3))\n",
    "    y = np.zeros((n_samples , 1))\n",
    "    return x , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f57e9-078a-4f7e-9bca-67774503e8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x , y = generate_fake_samples(64)\n",
    "pyplot.imshow(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae67f38-73c6-4537-8855-b42fae41821d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_discriminator(model , dataset , n_iter=20 , n_batch = 120):\n",
    "    half_batch = int(n_batch/2)\n",
    "    #manually enumerate epochs\n",
    "    for i in range(n_iter):\n",
    "        x_real , y_real = generate_real_sample(dataset , half_batch)\n",
    "        _ , real_acc = model.train_on_batch(x_real , y_real)\n",
    "        x_fake , y_fake = generate_fake_samples(half_batch)\n",
    "        _, fake_acc = model.train_on_batch(x_fake , y_fake)\n",
    "        print('> %d real=%.0f%% fake=%.0f%%' %(i+1, real_acc*100 , fake_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3288edf-3de5-4c4d-a6a6-bafbe703ee19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = define_discriminator()\n",
    "dataset = load_real_sample()\n",
    "train_discriminator(model , dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bee668-fdc6-429e-b605-5c951693ed7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51c902-b467-4db7-b2d0-c9373cfe48a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    #foundation for 4*4 image \n",
    "    n_node = 256*4*4\n",
    "    model.add(Dense(n_node , input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((4 , 4, 256)))\n",
    "    model.add(Conv2DTranspose(128 , (4, 4) , strides=(2, 2) , padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128 , (4, 4) , strides=(2, 2) , padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2DTranspose(128 , (4, 4) , strides=(2, 2) , padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #output layer\n",
    "    model.add(Conv2D(3 , (3, 3) , activation='tanh' , padding='same'))\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05db82-5205-4367-bfc1-9ef9bce8f664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "model = define_generator(latent_dim)\n",
    "model.summary()\n",
    "plot_model(model, to_file='generator_plot.png' , show_shapes=True , show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e918d6c4-5256-4d48-9f36-e48f8746a72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model , d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    #compile model \n",
    "    opt = Adam(lr=0.002 , beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy' , optimizer=opt)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf3426-c9b8-449c-a087-c2e1f1ec2550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model , d_model)\n",
    "gan_model.summary()\n",
    "plot_model(model, to_file='generator_plot.png' , show_shapes=True , show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699de697-e898-45bb-8465-0158d50e6cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(g_model , d_model , gan_model , dataset , latent_dim , n_epochs=200 , n_batch=120):\n",
    "    bat_per_epo = int(dataset.shape[0] /n_batch)\n",
    "    half_batch = int(n_batch/2)\n",
    "    #manually enumerate epochs\n",
    "    for i in range(bat_per_epo):\n",
    "        #get randomly select 'real' samples\n",
    "        x_real , y_real = generate_real_sample(dataset , half_batch)\n",
    "        d_loss_1, _ = d_model.train_on_batch(x_real , y_real)\n",
    "        x_fake , y_fake = generate_fake_samples(g_model , latent_dim , half_batch)\n",
    "        d_loss_2 , _ = d_model.train_on_batch(x_fake , y_fake)\n",
    "        \n",
    "        x_gan = generate_latent_points(latent_dim , n_batch)\n",
    "        #create inverted labels for the fake samples\n",
    "        y_gan = np.ones((n_batch , 1))\n",
    "        g_loss = gan_model.train_on_batch(x_gan , y_gan)\n",
    "        print('>%d , %d%d , d1=%.3f , d2=%.3f g=%.3f' %(i+1,j+1, bat_per_epo, d_loss_1 , d_loss_2 , g_loss))\n",
    "        if (i+1) % 10 ==0:\n",
    "            summarize_performance(i , g_model , d_model , dataset , latent_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635420f-ba56-4425-a5b4-c20629b3f412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize_performance(epoch , g_model , d_model , dataset , latent_dim , n_sample=150):\n",
    "    x_real , y_real = generate_real_sample(dataset , n_sample)\n",
    "    _ , acc_real = d_model.evaluate(x_real , y_real , verbose=0)\n",
    "    x_fake , y_fake = generate_fake_samples(g_model , latent_dim , n_sample)\n",
    "    _ , acc_real = d_model.evaluate(x_fake , y_fake , verbose=0)\n",
    "    print(\"> Accuracy real : %.0f%, fake : %.0f%%\" %(acc_real*100 , acc_fake*100))\n",
    "    save_plot(x_fake , epoch)\n",
    "    filename = 'generator_model_%03.h5' %(epoch+1)\n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d70ab-3f38-4da4-9409-6ccbb3e883fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_plot(example , epoch , n =7):\n",
    "    example = (example +1)/2.0\n",
    "    for i in range(n *n):\n",
    "        pyplot.subplot(n  , n , 1+i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(example[i])\n",
    "    filename = 'generated_plot_e%03d.png' %(epoch+1)\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6db00-35fe-4162-9933-36b05bc73a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train(g_model , d_model , gan_model , dataset ,latent_dim , n_epochs=200 , n_batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986528f2-5769-4ef4-909a-d35f2f876870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222f89c-46e5-42a1-9968-18d9dceeb0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a013332f-2d5f-459d-9d82-46c1a4a349f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
