{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9f42be-40b1-41a6-bbd7-71d298f75140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting helpers\n",
      "  Downloading helpers-0.2.0-py3-none-any.whl (2.3 kB)\n",
      "Installing collected packages: helpers\n",
      "Successfully installed helpers-0.2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install helpers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input, Flatten, Reshape\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f12c7e-2946-409c-91e1-298379ac6a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x203ed123e90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dc867d1-c995-4bba-a3a4-9c909b113650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initializer = RandomNormal(mean=0.0, stddev=0.01, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad44915-f248-4633-ad83-d6b64dcec103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AAN():\n",
    "    def __init__(self, img_shape=(28, 28), encoded_dim=2):\n",
    "        self.encoded_dim = encoded_dim\n",
    "        self.optimizer_reconst = Adam(0.01)\n",
    "        self.optimizer_discriminator = Adam(0.01)\n",
    "        self._initAndCompileFullModel(img_shape, encoded_dim)\n",
    "\n",
    "    def _genEncoderModel(self, img_shape, encoded_dim):\n",
    "        \"\"\" Build Encoder Model Based on Paper Configuration\n",
    "        Args:\n",
    "            img_shape (tuple) : shape of input image\n",
    "            encoded_dim (int) : number of latent variables\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "        encoder = Sequential()\n",
    "        encoder.add(Flatten(input_shape=img_shape))\n",
    "        encoder.add(Dense(1000, activation='relu', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        encoder.add(Dense(1000, activation='relu', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        encoder.add(Dense(encoded_dim, kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        encoder.summary()\n",
    "        return encoder\n",
    "\n",
    "    def _getDecoderModel(self, encoded_dim, img_shape):\n",
    "        \"\"\" Build Decoder Model Based on Paper Configuration\n",
    "        Args:\n",
    "            encoded_dim (int) : number of latent variables\n",
    "            img_shape (tuple) : shape of target images\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "        decoder = Sequential()\n",
    "        decoder.add(Dense(1000, activation='relu', input_dim=encoded_dim, kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        decoder.add(Dense(1000, activation='relu', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        decoder.add(Dense(np.prod(img_shape), activation='sigmoid', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        decoder.add(Reshape(img_shape))\n",
    "        decoder.summary()\n",
    "        return decoder\n",
    "\n",
    "    def _getDescriminator(self, encoded_dim):\n",
    "        \"\"\" Build Descriminator Model Based on Paper Configuration\n",
    "        Args:\n",
    "            encoded_dim (int) : number of latent variables\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "        discriminator = Sequential()\n",
    "        discriminator.add(Dense(1000, activation='relu',\n",
    "                                input_dim=encoded_dim, kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        discriminator.add(Dense(1000, activation='relu', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        discriminator.add(Dense(1, activation='sigmoid', kernel_initializer=initializer,\n",
    "                bias_initializer=initializer))\n",
    "        discriminator.summary()\n",
    "        return discriminator\n",
    "\n",
    "    def _initAndCompileFullModel(self, img_shape, encoded_dim):\n",
    "        self.encoder = self._genEncoderModel(img_shape, encoded_dim)\n",
    "        self.decoder = self._getDecoderModel(encoded_dim, img_shape)\n",
    "        self.discriminator = self._getDescriminator(encoded_dim)\n",
    "        img = Input(shape=img_shape)\n",
    "        encoded_repr = self.encoder(img)\n",
    "        gen_img = self.decoder(encoded_repr)\n",
    "        self.autoencoder = Model(img, gen_img)\n",
    "        valid = self.discriminator(encoded_repr)\n",
    "        self.encoder_discriminator = Model(img, valid)\n",
    "        self.discriminator.compile(optimizer=self.optimizer_discriminator,\n",
    "                                   loss='binary_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "        self.autoencoder.compile(optimizer=self.optimizer_reconst,\n",
    "                                 loss ='mse')\n",
    "        for layer in self.discriminator.layers:\n",
    "            layer.trainable = False\n",
    "        self.encoder_discriminator.compile(optimizer=self.optimizer_discriminator,\n",
    "                                           loss='binary_crossentropy',\n",
    "                                           metrics=['accuracy'])\n",
    "    def imagegrid(self, epochnumber):\n",
    "        fig = plt.figure(figsize=[20, 20])\n",
    "        images = self.generateImages(100)\n",
    "        for index,img in enumerate(images):\n",
    "            img = img.reshape((28, 28))\n",
    "            ax = fig.add_subplot(10, 10, index+1)\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        fig.savefig(\"images/AAE/\"+str(epochnumber)+\".png\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    def generateImages(self, n=100):\n",
    "        latents = 5*np.random.normal(size=(n, self.encoded_dim))\n",
    "        imgs = self.decoder.predict(latents)\n",
    "        return imgs\n",
    "\n",
    "    def train(self, x_train, batch_size=100, epochs=5000, save_interval=500):\n",
    "        half_batch = int(batch_size / 2)\n",
    "        for epoch in range(epochs):\n",
    "            #---------------Train Discriminator -------------\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
    "            imgs = x_train[idx]\n",
    "            # Generate a half batch of new images\n",
    "            latent_fake = self.encoder.predict(imgs)\n",
    "            #gen_imgs = self.decoder.predict(latent_fake)\n",
    "            latent_real = 5*np.random.normal(size=(half_batch, self.encoded_dim))\n",
    "            valid = np.ones((half_batch, 1))\n",
    "            fake = np.zeros((half_batch, 1))\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(latent_real, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(latent_fake, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs = x_train[idx]\n",
    "            # Generator wants the discriminator to label the generated representations as valid\n",
    "            valid_y = np.ones((batch_size, 1))\n",
    "\n",
    "            # Train the autoencode reconstruction\n",
    "            g_loss_reconstruction = self.autoencoder.train_on_batch(imgs, imgs)\n",
    "\n",
    "            # Train generator\n",
    "            g_logg_similarity = self.encoder_discriminator.train_on_batch(imgs, valid_y)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G acc: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1],\n",
    "                   g_logg_similarity[1], g_loss_reconstruction))\n",
    "            if(epoch % save_interval == 0):\n",
    "                self.imagegrid(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10177ad-8e9b-4ca8-b78a-fe559e4e4831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1000)              785000    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8)                 8008      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1794008 (6.84 MB)\n",
      "Trainable params: 1794008 (6.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 1000)              9000      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 784)               784784    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 28, 28)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1794784 (6.85 MB)\n",
      "Trainable params: 1794784 (6.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1000)              9000      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1011001 (3.86 MB)\n",
      "Trainable params: 1011001 (3.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "2/2 [==============================] - 1s 21ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1130, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 233, in _update_step\n        raise KeyError(\n\n    KeyError: 'The optimizer cannot recognize variable dense_9/kernel:0. This usually means you are trying to call the optimizer to update different parts of the model separately. Please call `optimizer.build(variables)` with the full list of trainable variables before the training loop or use legacy optimizer `tf.keras.optimizers.legacy.Adam.'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m\n\u001b[0;32m      6\u001b[0m ann \u001b[38;5;241m=\u001b[39m AAN(encoded_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m ann\u001b[38;5;241m.\u001b[39mtrain(x_train)\n\u001b[0;32m      8\u001b[0m generated \u001b[38;5;241m=\u001b[39m ann\u001b[38;5;241m.\u001b[39mgenerateImages(\u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m      9\u001b[0m L\u001b[38;5;241m=\u001b[39m helpers\u001b[38;5;241m.\u001b[39mapproximateLogLiklihood(generated, x_test)\n",
      "Cell \u001b[1;32mIn[6], line 127\u001b[0m, in \u001b[0;36mAAN.train\u001b[1;34m(self, x_train, batch_size, epochs, save_interval)\u001b[0m\n\u001b[0;32m    124\u001b[0m g_loss_reconstruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, imgs)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m g_logg_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, valid_y)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Plot the progress\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m [D loss: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, acc: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m] [G acc: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, mse: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, d_loss[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39md_loss[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    130\u001b[0m        g_logg_similarity[\u001b[38;5;241m1\u001b[39m], g_loss_reconstruction))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:2763\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2759\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2760\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2761\u001b[0m     )\n\u001b[0;32m   2762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2763\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   2765\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileq2ku3257.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:1360\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     run_step \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[0;32m   1357\u001b[0m         run_step, jit_compile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_retracing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m     )\n\u001b[0;32m   1359\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1360\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(run_step, args\u001b[38;5;241m=\u001b[39m(data,))\n\u001b[0;32m   1361\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1362\u001b[0m     outputs,\n\u001b[0;32m   1363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m   1364\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_reduction_method,\n\u001b[0;32m   1365\u001b[0m )\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:1349\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_step(data)\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py:1130\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:544\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[1;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m  None\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[1;32m--> 544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1223\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[0;32m   1222\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[1;32m-> 1223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:652\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[0;32m    651\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m--> 652\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m    654\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1253\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor:\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[1;32m-> 1253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39minterim\u001b[38;5;241m.\u001b[39mmaybe_merge_call(\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_apply_gradients_fn,\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy,\n\u001b[0;32m   1256\u001b[0m     grads_and_vars,\n\u001b[0;32m   1257\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1345\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[1;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[1;32m-> 1345\u001b[0m     distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m   1346\u001b[0m         var, apply_grad_to_update_var, args\u001b[38;5;241m=\u001b[39m(grad,), group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[0;32m   1350\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1342\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step_xla(grad, var, \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(var)))\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:233\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(variable) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_dict:\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe optimizer cannot recognize variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvariable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate different parts of the model separately. Please call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimizer.build(variables)` with the full list of trainable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariables before the training loop or use legacy optimizer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(gradient, variable)\n",
      "\u001b[1;31mKeyError\u001b[0m: in user code:\n\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1130, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 544, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1223, in apply_gradients\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 652, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1253, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1345, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 1342, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"C:\\Users\\asus\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py\", line 233, in _update_step\n        raise KeyError(\n\n    KeyError: 'The optimizer cannot recognize variable dense_9/kernel:0. This usually means you are trying to call the optimizer to update different parts of the model separately. Please call `optimizer.build(variables)` with the full list of trainable variables before the training loop or use legacy optimizer `tf.keras.optimizers.legacy.Adam.'\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.astype(np.float32) / 255.\n",
    "    x_test = x_test.astype(np.float32) / 255.\n",
    "    ann = AAN(encoded_dim=8)\n",
    "    ann.train(x_train)\n",
    "    generated = ann.generateImages(10000)\n",
    "    L= helpers.approximateLogLiklihood(generated, x_test)\n",
    "    print(\"Log Likelihood\")\n",
    "    print(L)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4de8257-8b32-4765-a553-1c9f4959707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, encoded_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(encoded_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 28 * 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        x = x.view(x.size(0), 1, 28, 28)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, encoded_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(encoded_dim, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class AAN:\n",
    "    def __init__(self, encoded_dim=8):\n",
    "        self.encoded_dim = encoded_dim\n",
    "\n",
    "        self.encoder = Encoder(encoded_dim)\n",
    "        self.decoder = Decoder(encoded_dim)\n",
    "        self.discriminator = Discriminator(encoded_dim)\n",
    "\n",
    "        self.optimizer_reconst = optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=0.01)\n",
    "        self.optimizer_discriminator = optim.Adam(self.discriminator.parameters(), lr=0.01)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def generateImages(self, n=100):\n",
    "        latents = 5 * torch.randn(n, self.encoded_dim)\n",
    "        imgs = self.decoder(latents)\n",
    "        return imgs\n",
    "\n",
    "    def train(self, train_loader, epochs=5000, batch_size=100, save_interval=500):\n",
    "        for epoch in range(epochs):\n",
    "            for i, data in enumerate(train_loader):\n",
    "                imgs, _ = data\n",
    "                batch_size = imgs.size(0)\n",
    "                valid = torch.ones(batch_size, 1)\n",
    "                fake = torch.zeros(batch_size, 1)\n",
    "\n",
    "                # Train Discriminator\n",
    "                latent_real = 5 * torch.randn(batch_size, self.encoded_dim)\n",
    "                latent_fake = self.encoder(imgs)\n",
    "                d_real_loss = self.bce_loss(self.discriminator(latent_real), valid)\n",
    "                d_fake_loss = self.bce_loss(self.discriminator(latent_fake), fake)\n",
    "                d_loss = 0.5 * (d_real_loss + d_fake_loss)\n",
    "                \n",
    "                self.optimizer_discriminator.zero_grad()\n",
    "                d_loss.backward()\n",
    "                self.optimizer_discriminator.step()\n",
    "\n",
    "                # Train Autoencoder\n",
    "                reconst_imgs = self.decoder(latent_fake)\n",
    "                ae_loss = self.criterion(reconst_imgs, imgs)\n",
    "                # Train Autoencoder\n",
    "\n",
    "\n",
    "                self.optimizer_reconst.zero_grad()\n",
    "                ae_loss.backward(retain_graph=True)  # Set retain_graph=True here\n",
    "                self.optimizer_reconst.step()\n",
    "                # Train Generator\n",
    "                g_loss = self.bce_loss(self.discriminator(latent_fake), valid)\n",
    "\n",
    "                self.optimizer_discriminator.zero_grad()\n",
    "                g_loss.backward()\n",
    "                self.optimizer_discriminator.step()\n",
    "\n",
    "                # Print the progress\n",
    "                print(f\"{epoch} [D loss: {d_loss.item()}, G loss: {g_loss.item()}, AE loss: {ae_loss.item()}]\")\n",
    "\n",
    "                if epoch % save_interval == 0:\n",
    "                    self.imagegrid(epoch)\n",
    "\n",
    "    def imagegrid(self, epochnumber):\n",
    "        fig = plt.figure(figsize=[20, 20])\n",
    "        images = self.generateImages(100)\n",
    "        for index, img in enumerate(images):\n",
    "            img = img.view(28, 28).detach().cpu().numpy()\n",
    "            ax = fig.add_subplot(10, 10, index + 1)\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "        plt.savefig(f\"images/AAE/{epochnumber}.png\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6356f859-1123-43ea-9bd0-b4c07b172c66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      7\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform), \n\u001b[0;32m      8\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the AAN model (you should train it before visualizing the output)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m ann\u001b[38;5;241m.\u001b[39mtrain(train_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize the output by generating and displaying images\u001b[39;00m\n\u001b[0;32m     15\u001b[0m ann\u001b[38;5;241m.\u001b[39mimagegrid(epochnumber)\n",
      "Cell \u001b[1;32mIn[8], line 93\u001b[0m, in \u001b[0;36mAAN.train\u001b[1;34m(self, train_loader, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m     90\u001b[0m ae_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(reconst_imgs, imgs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_reconst\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 93\u001b[0m ae_loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Set retain_graph=True here\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_reconst\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# Create an instance of the AAN model (assuming you've already created the model)\n",
    "ann = AAN(encoded_dim=8)\n",
    "\n",
    "# Load MNIST dataset (or FashionMNIST, as you prefer)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True, transform=transform), \n",
    "    batch_size=100, shuffle=True\n",
    ")\n",
    "\n",
    "# Train the AAN model (you should train it before visualizing the output)\n",
    "ann.train(train_loader, epochs=5000)\n",
    "\n",
    "# Visualize the output by generating and displaying images\n",
    "ann.imagegrid(epochnumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107a32cf-5044-44e2-babe-d1c5bad15255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
